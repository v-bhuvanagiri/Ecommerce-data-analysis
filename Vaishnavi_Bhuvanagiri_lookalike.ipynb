{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d3f1353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d8fe842",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = pd.read_csv(r\"C:\\SNU\\Sem 7\\z_assignment\\Customers.csv\")\n",
    "transactions = pd.read_csv(r\"C:\\SNU\\Sem 7\\z_assignment\\Transactions.csv\")\n",
    "products = pd.read_csv(r\"C:\\SNU\\Sem 7\\z_assignment\\products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7ef7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity\n",
    "products.rename(columns={\"Price\": \"CostPrice\"}, inplace=True)\n",
    "transactions.rename(columns={\"Price\": \"SellingPrice\"}, inplace=True)\n",
    "\n",
    "# Merge datasets\n",
    "merged_data = transactions.merge(customers, on=\"CustomerID\", how=\"inner\").merge(products, on=\"ProductID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c55fd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by customer to aggregate numerical and categorical features\n",
    "customer_features = merged_data.groupby('CustomerID').agg({\n",
    "    'TotalValue': 'sum',\n",
    "    'Quantity': 'sum',\n",
    "    'Category': lambda x: list(x),  # Collect all categories purchased\n",
    "    'Region': 'first'  # Take the first region (assumes one region per customer)\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "153e8a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Normalize Numeric Features\n",
    "numeric_features = ['TotalValue', 'Quantity']\n",
    "scaler = StandardScaler()\n",
    "normalized_numeric = scaler.fit_transform(customer_features[numeric_features])\n",
    "\n",
    "# Compute Canberra Distance for normalized numeric data\n",
    "canberra_distance = pairwise_distances(normalized_numeric, metric='canberra')\n",
    "\n",
    "# Step 3: Combine Canberra Distance and Jaccard Similarity\n",
    "# Normalize Canberra Distance to range [0, 1]\n",
    "normalized_canberra = 1 - (canberra_distance / np.max(canberra_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7c3fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Categorical Features\n",
    "categories = list(set([cat for sublist in customer_features['Category'] for cat in sublist]))\n",
    "for category in categories:\n",
    "    customer_features[category] = customer_features['Category'].apply(lambda x: 1 if category in x else 0)\n",
    "\n",
    "binary_matrix = customer_features[categories]\n",
    "\n",
    "# Convert to NumPy array and compute Jaccard Similarity\n",
    "binary_matrix_np = binary_matrix.to_numpy().astype(bool)\n",
    "jaccard_similarity = 1 - pairwise_distances(binary_matrix_np, metric='jaccard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "491aefb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both metrics with weights\n",
    "w1, w2 = 0.5, 0.5  # Adjust weights as needed\n",
    "final_similarity = w1 * normalized_canberra + w2 * jaccard_similarity\n",
    "\n",
    "# Step 4: Recommend Top 3 Lookalikes for Each Customer\n",
    "customer_ids = customer_features['CustomerID'].tolist()\n",
    "lookalike_results = {}\n",
    "\n",
    "for idx, customer_id in enumerate(customer_ids[:20]):  # First 20 customers (C0001 - C0020)\n",
    "    similarities = list(enumerate(final_similarity[idx]))\n",
    "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "    top_3 = [(customer_ids[i], round(score, 3)) for i, score in similarities[1:4]]  # Exclude self\n",
    "    lookalike_results[customer_id] = top_3\n",
    "\n",
    "# Step 5: Create Lookalike CSV\n",
    "lookalike_df = pd.DataFrame({\n",
    "    'CustomerID': list(lookalike_results.keys()),\n",
    "    'Lookalikes': [str(value) for value in lookalike_results.values()]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4da91149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vaishnavi_Bhuvanagiri_Lookalike.csv has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "lookalike_df.to_csv('Vaishnavi_Bhuvanagiri_Lookalike.csv', index=False)\n",
    "print(\"Vaishnavi_Bhuvanagiri_Lookalike.csv has been created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a968229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2874a679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
